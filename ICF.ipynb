{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error,recall_score,ndcg_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "np.corrcoef\n",
    "Return Pearson product-moment correlation coefficients.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst): \n",
    "\treturn round(sum(lst) / len(lst),4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie = np.load('../hw3_data/Movielens/user_movie.npy')\n",
    "\n",
    "X = user_movie[:,:2]\n",
    "y = user_movie[:,-1]\n",
    "entity_user = 943\n",
    "entity_item = 1682\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_business = np.load('../hw3_data/Yelp/user_business.npy')\n",
    "X = user_business[:,:2]\n",
    "y = user_business[:,-1]\n",
    "entity_user = 16239\n",
    "entity_item = 14284\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_book = np.load('../hw3_data/Douban_Book/user_book.npy')\n",
    "\n",
    "X = user_book[:,:2]\n",
    "y = user_book[:,-1]\n",
    "entity_user = 13024\n",
    "entity_item = 22347\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.1845996132128827, Recall: 0.3182136037223313, NDCG: 0.48038195458593536\n",
      "RMSE: 1.1955258151307064, Recall: 0.3159140421182862, NDCG: 0.4801534308867931\n",
      "RMSE: 1.1919513820662302, Recall: 0.31717812861407707, NDCG: 0.48285198893389125\n",
      "RMSE: 1.1827773090517415, Recall: 0.31837497646647483, NDCG: 0.4818143259783191\n",
      "RMSE: 1.188011021120685, Recall: 0.3178505150480084, NDCG: 0.4818504324651894\n",
      "Average RMSE: 1.1886, Average Recall: 0.3175, Average NDCG: 0.4814\n"
     ]
    }
   ],
   "source": [
    "#User-based CF\n",
    "RMSE_M = []\n",
    "recall_M = []\n",
    "NDCG_M = []\n",
    "weight_sum = True\n",
    "for i, (train_index, test_index) in enumerate(rs.split(X)):\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "    item_rating = np.zeros((entity_item, entity_user), dtype=int)\n",
    "    for i in range(y_train.shape[0]):\n",
    "        user, item = X_train[i]\n",
    "        item_rating[item-1, user-1] = y_train[i]\n",
    "        \n",
    "    ICF = np.corrcoef(item_rating)\n",
    "    #ICF = cosine_similarity(item_rating)\n",
    "    ICF[np.isnan(ICF)] = 0\n",
    "\n",
    "    Mu = item_rating.sum()/np.count_nonzero(item_rating)\n",
    "    dev_user, dev_item = np.std(item_rating,axis=0), np.std(item_rating,axis=1)\n",
    "\n",
    "    predict = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "\n",
    "        user, item =  X_test[i]\n",
    "        most_similar_item = np.argpartition(ICF[item-1],-6)[-6:-1]\n",
    "        msi_weight = ICF[item-1][most_similar_item]\n",
    "        rank = item_rating[most_similar_item, user-1]\n",
    "\n",
    "        if weight_sum == True:\n",
    "            bu = dev_user[user-1]-Mu\n",
    "            bi = dev_item[item-1]-Mu\n",
    "            bj = dev_item[most_similar_item]-Mu\n",
    "            bui = Mu + bu + bi\n",
    "            buj = Mu + bu + bj\n",
    "            weight_rank = (rank-buj)*msi_weight\n",
    "            # weight_rank = rank*msi_weight\n",
    "            if msi_weight.sum() == 0 :\n",
    "                predict.append(0)\n",
    "            else:\n",
    "                # pred = bui+ weight_rank.sum()/msi_weight.sum()\n",
    "                pred = weight_rank.sum()/msi_weight.sum()\n",
    "                predict.append(pred)\n",
    "        else:\n",
    "            pred = rank.sum()/5\n",
    "            predict.append(pred)\n",
    "    \n",
    "    RMSE = mean_squared_error(np.array(predict),y_test, squared=False)\n",
    "    RMSE_M.append(RMSE)\n",
    "    recall = recall_score(np.round(np.array(predict)),y_test, average='micro')\n",
    "    recall_M.append(recall)\n",
    "    NDCG = ndcg_score(np.array([predict]),y_test.reshape(1, -1), k=10)\n",
    "    NDCG_M.append(NDCG) \n",
    "    print(f\"RMSE: {RMSE}, Recall: {recall}, NDCG: {NDCG}\")\n",
    "print(f\"Average RMSE: {Average(RMSE_M)}, Average Recall: {Average(recall_M)}, Average NDCG: {Average(NDCG_M)}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 扣除所有使用者的加總平均，undo\n",
    "mean_by_user = user_rating.sum(axis=1)/np.count_nonzero(user_rating, axis=1)\n",
    "mean_by_user\n",
    "none_zero = np.where(user_rating > 0)\n",
    "none_zero[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
